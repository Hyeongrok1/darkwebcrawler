프로젝트에 사용된 라이브러리: beautifulSoup, nltk, request 등
beautifulSoup는 페이지의 html에서 원하는 데이터를 가져와서 파싱하는 유용한 라이브러리입니다.

본 크롤러는 하나의 다크웹 url을 크롤링한 후, 그 페이지에 있는 다른 다크웹 url을 타고 트리 형식으로 크롤링을 더 깊게 수행합니다.
그 과정에서 이미지와 본문을 다운로드하면서 그 url이 어떤 페이지인지 db에 저장합니다.
일련의 과정은 tor 브라우저를 통해서 이루어집니다.

코드의 프록시 설정은 tor 브라우저를 실행했을 때 다른 프로그램이 tor 네트워크를 사용할 수 있게 합니다(127.0.0.1:9150)

본문의 텍스트는 nltk 라이브러리를 이용해서 토큰화하여 명사만 쉼표로 구분해서 키워드로 저장합니다.

크롤링은 tor.py가 하고, server가 크롤링 결과를 json 형식으로 받아서 db에 저장합니다.

일단 server에 여러 클라이언트가 접근할 때 db입력이 동시에 일어나면 서버가 터져버리는 일이 있어서
db 입력 부분에 lock을 추가했습니다.
그리고 클라이언트가 각 웹사이트의 title을 뽑아오도록 수정했고
그리고 word cloud를 이용해서 각 카테고리 별로 많이 나온 키워드를 시각화해봤습니다.

